{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c546a52-fff2-49b0-95e4-1f224d90a6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "import requests  # ì›¹ì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¬ ë•Œ ì‚¬ìš©\n",
    "import openai  # OpenAI APIë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "from openai import OpenAI  # í´ë¼ì´ì–¸íŠ¸ ê°ì²´ ìƒì„±ìš©\n",
    "from typing import Dict, List, Tuple  # íƒ€ì… íŒíŠ¸ ì§€ì›\n",
    "import time  # ì‹œê°„ ì¸¡ì •ìš©\n",
    "import re  # ì •ê·œí‘œí˜„ì‹ (í˜„ì¬ ì½”ë“œì—ì„œëŠ” ì‚¬ìš©ë˜ì§€ ì•ŠìŒ)\n",
    "import pandas as pd  # ë°ì´í„°í”„ë ˆì„ ì‘ì—…ìš©\n",
    "import tiktoken  # í† í° ìˆ˜ ê³„ì‚° (GPTì˜ ì…ë ¥ ê¸¸ì´ ì¸¡ì •ìš©)\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# OpenAI API ì„¤ì •\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60341cc1-8095-49c4-b285-73ba62bf59d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TestResult:\n",
    "    model: str\n",
    "    prompt_method: str\n",
    "    correct_answers: int\n",
    "    total_questions: int\n",
    "    score: float\n",
    "    total_score: float\n",
    "    execution_time: float\n",
    "    detailed_results: pd.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e68c1230-fc15-4402-b272-993fec19556a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê°„ë‹¨í•˜ê²Œ ë‹¤ì‹œ ì‘ì„±í•œ í”„ë¡¬í”„íŠ¸\n",
    "\n",
    "PROMPTS = {\n",
    "    \"zero_shot\": \"\"\"ë‹¤ìŒ ì§€ë¬¸ì„ ì½ê³  ë¬¸ì œë¥¼ í’€ì–´ì£¼ì„¸ìš”.\n",
    "    \n",
    "    ì§€ë¬¸:\n",
    "    {paragraph}\n",
    "    \n",
    "    ë¬¸ì œ: {question}\n",
    "    {question_plus}\n",
    "    \n",
    "    ì„ íƒì§€:\n",
    "    {choices1}\n",
    "    {choices2}\n",
    "    {choices3}\n",
    "    {choices4}\n",
    "    {choices5}\n",
    "    \n",
    "    ìœ„ ë¬¸ì œì˜ ì •ë‹µì„ ë²ˆí˜¸ë¡œ ë‹µí•´ì£¼ì„¸ìš”.\n",
    "    ì •ë‹µ: \"\"\",\n",
    "    \n",
    "    \"function_calling\": \"\"\"ë‹¤ìŒì€ í•œêµ­ì–´ ë…í•´ ë¬¸ì œì…ë‹ˆë‹¤. ì§€ë¬¸ì„ ë¶„ì„í•˜ê³  ë…¼ë¦¬ì ìœ¼ë¡œ ë‹µí•´ì£¼ì„¸ìš”.\n",
    "\n",
    "    ì§€ë¬¸:\n",
    "    {paragraph}\n",
    "\n",
    "    ë¬¸ì œ: {question}\n",
    "    {question_plus}\n",
    "\n",
    "    ì„ íƒì§€:\n",
    "    {choices1}\n",
    "    {choices2}\n",
    "    {choices3}\n",
    "    {choices4}\n",
    "    {choices5}\n",
    "\n",
    "    ë‹¤ìŒ ë‹¨ê³„ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:\n",
    "    1. ì§€ë¬¸ì˜ í•µì‹¬ ë‚´ìš© íŒŒì•…\n",
    "    2. ë¬¸ì œì—ì„œ ìš”êµ¬í•˜ëŠ” ê²ƒ ë¶„ì„\n",
    "    3. ê° ì„ íƒì§€ ê²€í† \n",
    "    4. ë…¼ë¦¬ì  ì¶”ë¡ ì„ í†µí•œ ì •ë‹µ ë„ì¶œ\n",
    "\n",
    "    ìµœì¢… ì •ë‹µ: \"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "979d7b43-022f-4ffb-a8d0-7b5b1dd1fbb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ ë°ì´í„° ë¡œë”© ì¤‘...\n",
      "ë°ì´í„° ë¡œë“œ ì™„ë£Œ: 45 ë¬¸ì œ\n",
      "ì „ì²´ ë¬¸ì œ ìˆ˜: 45\n",
      "í…ŒìŠ¤íŠ¸í•  ë¬¸ì œ ìˆ˜ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì—”í„° ì‹œ ì „ì²´): "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ğŸ¯ 2023 ìˆ˜ëŠ¥ êµ­ì–´ AI í’€ì´ í”„ë¡œê·¸ë¨\n",
      "============================================================\n",
      "ğŸ“Š í…ŒìŠ¤íŠ¸í•  ë¬¸ì œ ìˆ˜: 45\n",
      "ğŸ¤– ëª¨ë¸: gpt-4o-mini, gpt-4o\n",
      "ğŸ’¡ í”„ë¡¬í”„íŠ¸ ê¸°ë²•: function_calling, zero_shot\n",
      "============================================================\n",
      "\n",
      "í…ŒìŠ¤íŠ¸ ì‹œì‘: gpt-4o-mini + function_calling\n",
      "ë¬¸ì œ í’€ì´ ì¤‘: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 (100.0%)\n",
      "âœ… ì™„ë£Œ: function_calling + gpt-4o-mini\n",
      "   ì ìˆ˜: 48ì , ì •ë‹µë¥ : 48.9% (22/45)\n",
      "   ì†Œìš”ì‹œê°„: 892.981ì´ˆ\n",
      "----------------------------------------\n",
      "\n",
      "í…ŒìŠ¤íŠ¸ ì‹œì‘: gpt-4o-mini + zero_shot\n",
      "ë¬¸ì œ í’€ì´ ì¤‘: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 (100.0%)\n",
      "âœ… ì™„ë£Œ: zero_shot + gpt-4o-mini\n",
      "   ì ìˆ˜: 68ì , ì •ë‹µë¥ : 68.9% (31/45)\n",
      "   ì†Œìš”ì‹œê°„: 75.693ì´ˆ\n",
      "----------------------------------------\n",
      "\n",
      "í…ŒìŠ¤íŠ¸ ì‹œì‘: gpt-4o + function_calling\n",
      "ë¬¸ì œ í’€ì´ ì¤‘: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 (100.0%)\n",
      "âœ… ì™„ë£Œ: function_calling + gpt-4o\n",
      "   ì ìˆ˜: 74ì , ì •ë‹µë¥ : 73.3% (33/45)\n",
      "   ì†Œìš”ì‹œê°„: 403.781ì´ˆ\n",
      "----------------------------------------\n",
      "\n",
      "í…ŒìŠ¤íŠ¸ ì‹œì‘: gpt-4o + zero_shot\n",
      "ë¬¸ì œ í’€ì´ ì¤‘: |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45/45 (100.0%)\n",
      "âœ… ì™„ë£Œ: zero_shot + gpt-4o\n",
      "   ì ìˆ˜: 84ì , ì •ë‹µë¥ : 84.4% (38/45)\n",
      "   ì†Œìš”ì‹œê°„: 79.820ì´ˆ\n",
      "----------------------------------------\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š ìµœì¢… ê²°ê³¼ ë¶„ì„\n",
      "============================================================\n",
      "\n",
      "ğŸ“‹ í”„ë¡¬í”„íŠ¸ë³„ ê²°ê³¼ ìš”ì•½:\n",
      "  function_calling_gpt-4o-mini: ì ìˆ˜ 48, ì •ë‹µë¥  48.9%, ì‹œê°„ 892.981ì´ˆ\n",
      "  zero_shot_gpt-4o-mini: ì ìˆ˜ 68, ì •ë‹µë¥  68.9%, ì‹œê°„ 75.693ì´ˆ\n",
      "  function_calling_gpt-4o: ì ìˆ˜ 74, ì •ë‹µë¥  73.3%, ì‹œê°„ 403.781ì´ˆ\n",
      "  zero_shot_gpt-4o: ì ìˆ˜ 84, ì •ë‹µë¥  84.4%, ì‹œê°„ 79.820ì´ˆ\n",
      "\n",
      "ğŸ† ìµœê³  ì„±ëŠ¥: gpt-4o + zero_shot\n",
      "   ì ìˆ˜: 84ì  (38/45)\n",
      "\n",
      "ğŸ” í”„ë¡¬í”„íŠ¸ë³„ ì •ë‹µ/ì˜¤ë‹µ ì˜ˆì‹œ ë¶„ì„:\n",
      "\n",
      "#####\n",
      "1ë²ˆì§¸: function_calling_gpt-4o-mini í”„ë¡¬í”„íŠ¸ ë¶„ì„\n",
      "\n",
      "âœ… ì •ë‹µ ì˜ˆì‹œ:\n",
      "  ì˜ˆì¸¡: 1\n",
      "  ì •ë‹µ: 1\n",
      "  ì‘ë‹µ: 1. **ì§€ë¬¸ì˜ í•µì‹¬ ë‚´ìš© íŒŒì•…:**\n",
      "   - ë…ì„œëŠ” ì¦ê±°ì›€ì„ ì£¼ë©°, ê·¸ ì¤‘ì‹¬ì—ëŠ” â€˜ì†Œí†µì˜ ì¦ê±°ì›€â€™ì´ ìˆë‹¤.\n",
      "   - ë…ìëŠ” í•„ìì™€ ê°„ì ‘ì ìœ¼ë¡œ ëŒ€í™”í•˜ë©° ë‹¤ì–‘í•œ ì‚¶ì„ ê²½í—˜í•˜ê³  ì‹œì•¼ë¥¼ ë„“í ìˆ˜ ìˆë‹¤.\n",
      "   - ë…ìë“¤ì€ ì €ë§ˆë‹¤ ë‹¤ë¥¸ ê´€ì ê³¼ ë°°ê²½ìœ¼ë¡œ ì±…ê³¼ ì†Œí†µí•˜ë©°, ì´ ê³¼ì •ì—ì„œ ì§ˆë¬¸í•˜ê³  ë‹µì„ ì°¾ì•„ë‚¸ë‹¤.\n",
      "   - ë…ì„œ ëª¨ì„ì´ë‚˜ ë™ì•„ë¦¬ë¥¼ í†µí•´ ë‹¤ë¥¸ ë…ìì™€ ì†Œí†µí•˜ë©° ì¸...\n",
      "\n",
      "âŒ ì˜¤ë‹µ ì˜ˆì‹œ:\n",
      "  ì˜ˆì¸¡: 1\n",
      "  ì •ë‹µ: 4\n",
      "  ì‘ë‹µ: 1. **ì§€ë¬¸ì˜ í•µì‹¬ ë‚´ìš© íŒŒì•…**:\n",
      "   - ë…ì„œëŠ” ì¦ê±°ì›€ì˜ ì›ì²œì´ë©°, íŠ¹íˆ 'ì†Œí†µì˜ ì¦ê±°ì›€'ì´ ì¤‘ìš”í•˜ë‹¤.\n",
      "   - ë…ìëŠ” í•„ìì™€ ê°„ì ‘ì ìœ¼ë¡œ ëŒ€í™”í•˜ë©°, ë‹¤ì–‘í•œ ì‚¶ì„ ê²½í—˜í•˜ê³  ì´í•´í•˜ê²Œ ëœë‹¤.\n",
      "   - ê° ë…ìëŠ” ë…ì„œ í™˜ê²½, ë°°ê²½ì§€ì‹, ê´€ì  ë“±ì— ë”°ë¼ ì„œë¡œ ë‹¤ë¥¸ ì˜ë¯¸ë¥¼ êµ¬ì„±í•  ìˆ˜ ìˆë‹¤.\n",
      "   - ë…ìëŠ” ì±…ê³¼ì˜ ì†Œí†µì„ í†µí•´ ë‹¤ë¥¸ ë…ìì™€ì˜ ì†Œí†µì„ í†µí•´ ê°œì¸ì˜ ì˜...\n",
      "\n",
      "\n",
      "#####\n",
      "2ë²ˆì§¸: zero_shot_gpt-4o-mini í”„ë¡¬í”„íŠ¸ ë¶„ì„\n",
      "\n",
      "âœ… ì •ë‹µ ì˜ˆì‹œ:\n",
      "  ì˜ˆì¸¡: 4\n",
      "  ì •ë‹µ: 4\n",
      "  ì‘ë‹µ: ì •ë‹µ: 4ë²ˆ...\n",
      "\n",
      "âŒ ì˜¤ë‹µ ì˜ˆì‹œ:\n",
      "  ì˜ˆì¸¡: 4\n",
      "  ì •ë‹µ: 5\n",
      "  ì‘ë‹µ: ì •ë‹µ: 4ë²ˆ...\n",
      "\n",
      "\n",
      "#####\n",
      "3ë²ˆì§¸: function_calling_gpt-4o í”„ë¡¬í”„íŠ¸ ë¶„ì„\n",
      "\n",
      "âœ… ì •ë‹µ ì˜ˆì‹œ:\n",
      "  ì˜ˆì¸¡: 5\n",
      "  ì •ë‹µ: 5\n",
      "  ì‘ë‹µ: 1. **ì§€ë¬¸ì˜ í•µì‹¬ ë‚´ìš© íŒŒì•…**:\n",
      "   ì§€ë¬¸ì€ ë…ì„œì˜ ì¦ê±°ì›€ ì¤‘ í•˜ë‚˜ì¸ ì†Œí†µì˜ ì¦ê±°ì›€ì— ëŒ€í•´ ì„¤ëª…í•˜ê³  ìˆë‹¤. ë…ìëŠ” ì±…ì„ í†µí•´ ë‹¤ì–‘í•œ ì„¸ê³„ì™€ ì†Œí†µí•˜ë©°, ìì‹ ì˜ ê´€ì ì— ë”°ë¼ ì„œë¡œ ë‹¤ë¥¸ ì˜ë¯¸ë¥¼ êµ¬ì„±í•  ìˆ˜ ìˆë‹¤. ì´ëŠ” ë…ìê°€ ì±…ì˜ ë‚´ìš©ì„ ì§ˆë¬¸í•˜ê³  ë‹µì„ ì°¾ëŠ” ê³¼ì •ì—ì„œ ê°€ëŠ¥í•´ì§€ë©°, ê·¸ ê³¼ì •ì—ì„œ ì†Œí†µì˜ ì¦ê±°ì›€ì´ ì¦ëŒ€ëœë‹¤. ë˜í•œ, ë…ìëŠ” ë‹¤ë¥¸ ë…ìì™€ì˜ ì†Œí†µì„ í†µí•´ ...\n",
      "\n",
      "âŒ ì˜¤ë‹µ ì˜ˆì‹œ:\n",
      "  ì˜ˆì¸¡: 1\n",
      "  ì •ë‹µ: 4\n",
      "  ì‘ë‹µ: 1. **ì§€ë¬¸ì˜ í•µì‹¬ ë‚´ìš© íŒŒì•…**  \n",
      "   ì§€ë¬¸ì€ ë…ì„œì˜ ì¦ê±°ì›€ ì¤‘ 'ì†Œí†µì˜ ì¦ê±°ì›€'ì— ëŒ€í•´ ì„¤ëª…í•©ë‹ˆë‹¤. ë…ìëŠ” ì±…ì„ í†µí•´ í•„ìì™€ ì†Œí†µí•˜ê³ , ë‹¤ì–‘í•œ ì‚¬íšŒì™€ ì‹œëŒ€ë¥¼ ê°„ì ‘ ê²½í—˜í•˜ë©°, ì„œë¡œ ë‹¤ë¥¸ ë…ìë“¤ê³¼ì˜ ì†Œí†µì„ í†µí•´ ì¸ì‹ì„ í™•ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë˜í•œ, ë…ìì˜ ë°°ê²½ì§€ì‹ê³¼ ê´€ì  ë“±ì´ ë…ì„œ ê³¼ì •ì— ì˜í–¥ì„ ë¯¸ì¹˜ë©°, ë…ì„œ í›„ ë‹¤ë¥¸ ë…ìì™€ì˜ ì˜ê²¬ êµí™˜ì„ í†µí•´ ë” ë‹¤ì–‘í•œ...\n",
      "\n",
      "\n",
      "#####\n",
      "4ë²ˆì§¸: zero_shot_gpt-4o í”„ë¡¬í”„íŠ¸ ë¶„ì„\n",
      "\n",
      "âœ… ì •ë‹µ ì˜ˆì‹œ:\n",
      "  ì˜ˆì¸¡: 4\n",
      "  ì •ë‹µ: 4\n",
      "  ì‘ë‹µ: 4ë²ˆ ë…ìì˜ ë°°ê²½ì§€ì‹, ê´€ì , ì½ê¸° í™˜ê²½, ê³¼ì œëŠ” ë…ìì˜ ì˜ë¯¸ êµ¬ì„±ì— ì˜í–¥ì„ ì£¼ëŠ” ë…ì ìš”ì¸ì´ë‹¤....\n",
      "\n",
      "âŒ ì˜¤ë‹µ ì˜ˆì‹œ:\n",
      "  ì˜ˆì¸¡: 4\n",
      "  ì •ë‹µ: 5\n",
      "  ì‘ë‹µ: 4ë²ˆ â“‘ì—ëŠ” â€˜ì±…ì—ì„œ ë‹µì„ ì°¾ëŠ” ì§ˆë¬¸â€™ì´, â“’ì—ëŠ” ê·¸ì— ëŒ€í•œ ë‹µì„ â€˜ì±…ì˜ ë‚´ìš©ë“¤ì„ ê´€ê³„ ì§€ìœ¼ë©°â€™ ì°¾ì•„ë‚´ëŠ” ëª¨ìŠµì´ ë‚˜íƒ€ë‚œë‹¤....\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 357\u001b[39m\n\u001b[32m    354\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mğŸ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m357\u001b[39m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 352\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    349\u001b[39m solver.analyze_results()\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# 5. ê²°ê³¼ ë‚´ë³´ë‚´ê¸°\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m352\u001b[39m \u001b[43msolver\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexport_detailed_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mğŸ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 308\u001b[39m, in \u001b[36mKoreanSuneungSolver.export_detailed_results\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    306\u001b[39m os.makedirs(\u001b[33m\"\u001b[39m\u001b[33mdata/results\u001b[39m\u001b[33m\"\u001b[39m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    307\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mdata/results/summary_results.json\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m, encoding=\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m--> \u001b[39m\u001b[32m308\u001b[39m     \u001b[43mjson\u001b[49m.dump(summary_data, f, ensure_ascii=\u001b[38;5;28;01mFalse\u001b[39;00m, indent=\u001b[32m2\u001b[39m)\n\u001b[32m    310\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    311\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m   - ìš”ì•½: data/results/summary_results.json\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'json' is not defined"
     ]
    }
   ],
   "source": [
    "class KoreanSuneungSolver:\n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "        self.results = {}\n",
    "        self.client = OpenAI()\n",
    "        self.tokenizer = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"GitHubì—ì„œ 2023ë…„ ìˆ˜ëŠ¥ êµ­ì–´ ë°ì´í„° ë¡œë“œ\"\"\"\n",
    "        github_url = \"https://raw.githubusercontent.com/NomaDamas/KICE_slayer_AI_Korean/master/data/2023_11_KICE.json\"\n",
    "        try:\n",
    "            response = requests.get(github_url, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            raw_data = response.json()\n",
    "            \n",
    "            # ë©˜í†  ì½”ë“œë¥¼ ë°˜ì˜í•œ ë°ì´í„° êµ¬ì¡° ë³€í™˜\n",
    "            total_result = []\n",
    "            for data in raw_data:\n",
    "                paragraph_id = data['id']\n",
    "                paragraph = data['paragraph']\n",
    "                data_type = data['type']\n",
    "                problems_lst = data['problems']\n",
    "                \n",
    "                for problem in problems_lst:\n",
    "                    question = problem['question']\n",
    "                    # ì„ íƒì§€ë¥¼ \"1ë²ˆ ë‚´ìš©\" í˜•íƒœë¡œ ë³€í™˜\n",
    "                    choices = [f\"{i+1}ë²ˆ {choice}\" for i, choice in enumerate(problem['choices'])]\n",
    "                    answer = problem['answer']\n",
    "                    score = problem['score']\n",
    "                    question_plus = problem.get('question_plus', '')\n",
    "                    \n",
    "                    problem_dict = {\n",
    "                        'paragraph_id': paragraph_id,\n",
    "                        'type': data_type,\n",
    "                        'paragraph': paragraph,\n",
    "                        'question': question,\n",
    "                        'question_plus': question_plus,\n",
    "                        'choices': choices,\n",
    "                        'answer': answer,\n",
    "                        'score': score,\n",
    "                    }\n",
    "                    total_result.append(problem_dict)\n",
    "            \n",
    "            self.data = total_result\n",
    "            print(f\"ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.data)} ë¬¸ì œ\")\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def normalize_answer(self, text: str) -> int:\n",
    "        \"\"\"ë‹µì•ˆ ì •ê·œí™”\"\"\"\n",
    "        if hasattr(text, 'content'):\n",
    "            result = text.content\n",
    "        else:\n",
    "            result = str(text)\n",
    "        \n",
    "        result = result.split(\"ì •ë‹µ:\")[-1]\n",
    "        for num in range(1, 6):\n",
    "            if str(num) in result:\n",
    "                return num\n",
    "        \n",
    "        return random.randint(1, 5)\n",
    "    \n",
    "    def prediction(self, prompt: str, model: str = \"gpt-4o\"):\n",
    "        \"\"\"OpenAI API í˜¸ì¶œ\"\"\"\n",
    "        try:\n",
    "            completion = self.client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "            )\n",
    "            return completion.choices[0].message\n",
    "        except Exception as e:\n",
    "            print(f\"API í˜¸ì¶œ ì‹¤íŒ¨: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def build_prompts(self, prompt_name: str) -> List[str]:\n",
    "        \"\"\"íŠ¹ì • í”„ë¡¬í”„íŠ¸ íƒ€ì…ìœ¼ë¡œ ëª¨ë“  ë¬¸ì œì— ëŒ€í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±\"\"\"\n",
    "        if prompt_name not in PROMPTS:\n",
    "            raise ValueError(f\"ì§€ì›í•˜ì§€ ì•ŠëŠ” í”„ë¡¬í”„íŠ¸: {prompt_name}\")\n",
    "        \n",
    "        prompt_template = PROMPTS[prompt_name]\n",
    "        prompt_lst = []\n",
    "        \n",
    "        for data in self.data:\n",
    "            # question_plusê°€ ë¹„ì–´ìˆì„ ê²½ìš° ì²˜ë¦¬\n",
    "            question_plus_text = f\"ì¶”ê°€ ì •ë³´: {data['question_plus']}\" if data['question_plus'] else \"\"\n",
    "            \n",
    "            prompt = prompt_template.format(\n",
    "                paragraph=data['paragraph'],\n",
    "                question=data['question'],\n",
    "                question_plus=question_plus_text,\n",
    "                choices1=data['choices'][0],\n",
    "                choices2=data['choices'][1],\n",
    "                choices3=data['choices'][2],\n",
    "                choices4=data['choices'][3],\n",
    "                choices5=data['choices'][4],\n",
    "            )\n",
    "            prompt_lst.append(prompt)\n",
    "        \n",
    "        return prompt_lst\n",
    "    \n",
    "    def run_test(self, prompt_name: str, model: str = \"gpt-4o\", max_questions: int = None) -> TestResult:\n",
    "        \"\"\"í”„ë¡¬í”„íŠ¸ë¡œ ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰\"\"\"\n",
    "        if self.data is None:\n",
    "            raise ValueError(\"ë°ì´í„°ë¥¼ ë¨¼ì € ë¡œë“œí•´ì£¼ì„¸ìš”.\")\n",
    "        \n",
    "        test_data = self.data[:max_questions] if max_questions else self.data\n",
    "        prompt_lst = self.build_prompts(prompt_name)[:len(test_data)]\n",
    "        \n",
    "        print(f\"\\ní…ŒìŠ¤íŠ¸ ì‹œì‘: {model} + {prompt_name}\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        pred_lst = []\n",
    "        answer_lst = []\n",
    "        score_lst = []\n",
    "        input_token_lst = []\n",
    "        output_token_lst = []\n",
    "        response_lst = []\n",
    "        \n",
    "        for i, (prompt, problem) in enumerate(zip(prompt_lst, test_data)):\n",
    "            try:\n",
    "                # ì§„í–‰ë¥  í‘œì‹œ\n",
    "                self.print_progress(i + 1, len(test_data), \"ë¬¸ì œ í’€ì´ ì¤‘\")\n",
    "                \n",
    "                # ì˜ˆì¸¡\n",
    "                result = self.prediction(prompt, model)\n",
    "                if result is None:\n",
    "                    pred = random.randint(1, 5)\n",
    "                    response_text = \"API í˜¸ì¶œ ì‹¤íŒ¨\"\n",
    "                else:\n",
    "                    pred = self.normalize_answer(result)\n",
    "                    response_text = result.content\n",
    "                \n",
    "                pred_lst.append(pred)\n",
    "                answer_lst.append(problem['answer'])\n",
    "                score_lst.append(problem['score'])\n",
    "                input_token_lst.append(len(self.tokenizer.encode(prompt)))\n",
    "                output_token_lst.append(len(self.tokenizer.encode(response_text)) if result else 0)\n",
    "                response_lst.append(response_text)\n",
    "                \n",
    "                # API ì œí•œ ê³ ë ¤í•˜ì—¬ ì ì‹œ ëŒ€ê¸°\n",
    "                time.sleep(0.5)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"\\në¬¸ì œ {i+1} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "                pred_lst.append(random.randint(1, 5))\n",
    "                answer_lst.append(problem['answer'])\n",
    "                score_lst.append(problem['score'])\n",
    "                input_token_lst.append(0)\n",
    "                output_token_lst.append(0)\n",
    "                response_lst.append(f\"ì˜¤ë¥˜: {str(e)}\")\n",
    "        \n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        \n",
    "        # DataFrame ìƒì„± (ë©˜í† ë‹˜ ì½”ë“œ êµ¬ì¡° ë°˜ì˜)\n",
    "        df = pd.DataFrame({\n",
    "            'pred': pred_lst,\n",
    "            'answer': answer_lst,\n",
    "            'score': score_lst,\n",
    "            'input_tokens': input_token_lst,\n",
    "            'output_tokens': output_token_lst,\n",
    "            'response': response_lst,\n",
    "            'time': execution_time,\n",
    "        })\n",
    "        \n",
    "        # ì •ë‹µ ì—¬ë¶€ ê³„ì‚°\n",
    "        df['result'] = df['pred'].apply(lambda x: int(x)) == df['answer'].apply(lambda x: int(x))\n",
    "        \n",
    "        # ê²°ê³¼ í†µê³„\n",
    "        correct_answers = df['result'].sum()\n",
    "        total_questions = len(df)\n",
    "        total_score = (df['result'] * df['score']).sum()\n",
    "        percentage = (correct_answers / total_questions) * 100\n",
    "        \n",
    "        # CSV ì €ì¥\n",
    "        os.makedirs(\"data/results\", exist_ok=True)\n",
    "        csv_path = f\"data/results/{prompt_name}_{model}.csv\"\n",
    "        df.to_csv(csv_path, index=False, encoding='utf-8')\n",
    "        \n",
    "        result = TestResult(\n",
    "            model=model,\n",
    "            prompt_method=prompt_name,\n",
    "            correct_answers=correct_answers,\n",
    "            total_questions=total_questions,\n",
    "            score=percentage,\n",
    "            total_score=total_score,\n",
    "            execution_time=execution_time,\n",
    "            detailed_results=df\n",
    "        )\n",
    "        \n",
    "        self.results[f\"{prompt_name}_{model}\"] = result\n",
    "        \n",
    "        print(f\"âœ… ì™„ë£Œ: {prompt_name} + {model}\")\n",
    "        print(f\"   ì ìˆ˜: {total_score}ì , ì •ë‹µë¥ : {percentage:.1f}% ({correct_answers}/{total_questions})\")\n",
    "        print(f\"   ì†Œìš”ì‹œê°„: {execution_time:.3f}ì´ˆ\")\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def print_progress(self, current: int, total: int, desc: str = \"ì§„í–‰ì¤‘\"):\n",
    "        \"\"\"ì§„í–‰ë¥  ì¶œë ¥ í•¨ìˆ˜\"\"\"\n",
    "        percentage = (current / total) * 100\n",
    "        bar_length = 30\n",
    "        filled_length = int(bar_length * current // total)\n",
    "        bar = 'â–ˆ' * filled_length + '-' * (bar_length - filled_length)\n",
    "        print(f'\\r{desc}: |{bar}| {current}/{total} ({percentage:.1f}%)', end='', flush=True)\n",
    "        if current == total:\n",
    "            print()\n",
    "    \n",
    "    def run_comprehensive_test(self, models: List[str] = None, max_questions: int = None):\n",
    "        \"\"\"ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰\"\"\"\n",
    "        if models is None:\n",
    "            models = [\"gpt-4o-mini\", \"gpt-4o\"]\n",
    "        \n",
    "        prompt_methods = [\"function_calling\", \"zero_shot\"]\n",
    "        \n",
    "        print(\"=\" * 60)\n",
    "        print(\"ğŸ¯ 2023 ìˆ˜ëŠ¥ êµ­ì–´ AI í’€ì´ í”„ë¡œê·¸ë¨\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"ğŸ“Š í…ŒìŠ¤íŠ¸í•  ë¬¸ì œ ìˆ˜: {max_questions if max_questions else len(self.data)}\")\n",
    "        print(f\"ğŸ¤– ëª¨ë¸: {', '.join(models)}\")\n",
    "        print(f\"ğŸ’¡ í”„ë¡¬í”„íŠ¸ ê¸°ë²•: {', '.join(prompt_methods)}\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        for model in models:\n",
    "            for prompt_method in prompt_methods:\n",
    "                try:\n",
    "                    self.run_test(prompt_method, model, max_questions)\n",
    "                    print(\"-\" * 40)\n",
    "                except Exception as e:\n",
    "                    print(f\"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨ - {model} + {prompt_method}: {e}\")\n",
    "    \n",
    "    def analyze_results(self):\n",
    "        \"\"\"ê²°ê³¼ ë¶„ì„ ë° ì¶œë ¥\"\"\"\n",
    "        if not self.results:\n",
    "            print(\"ë¶„ì„í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            return\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"ğŸ“Š ìµœì¢… ê²°ê³¼ ë¶„ì„\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # ê° í”„ë¡¬í”„íŠ¸ì— ëŒ€í•œ ê²°ê³¼ ìš”ì•½\n",
    "        print(\"\\nğŸ“‹ í”„ë¡¬í”„íŠ¸ë³„ ê²°ê³¼ ìš”ì•½:\")\n",
    "        for name, result in self.results.items():\n",
    "            print(f\"  {name}: ì ìˆ˜ {result.total_score}, ì •ë‹µë¥  {result.score:.1f}%, ì‹œê°„ {result.execution_time:.3f}ì´ˆ\")\n",
    "        \n",
    "        # ìµœê³  ì„±ëŠ¥ ì°¾ê¸°\n",
    "        if self.results:\n",
    "            best_result = max(self.results.values(), key=lambda x: x.score)\n",
    "            print(f\"\\nğŸ† ìµœê³  ì„±ëŠ¥: {best_result.model} + {best_result.prompt_method}\")\n",
    "            print(f\"   ì ìˆ˜: {best_result.total_score}ì  ({best_result.correct_answers}/{best_result.total_questions})\")\n",
    "        \n",
    "        # ìƒì„¸ ë¶„ì„ (ë©˜í† ë‹˜ ì½”ë“œì˜ ì •ë‹µ/ì˜¤ë‹µ ì˜ˆì‹œ ë°©ì‹)\n",
    "        self.show_sample_responses()\n",
    "    \n",
    "    def show_sample_responses(self):\n",
    "        \"\"\"ê° í”„ë¡¬í”„íŠ¸ íƒ€ì…ì— ëŒ€í•œ ì •ë‹µê³¼ ì˜¤ë‹µì˜ ì˜ˆì‹œ\"\"\"\n",
    "        print(f\"\\nğŸ” í”„ë¡¬í”„íŠ¸ë³„ ì •ë‹µ/ì˜¤ë‹µ ì˜ˆì‹œ ë¶„ì„:\")\n",
    "        \n",
    "        for i, (name, result) in enumerate(self.results.items()):\n",
    "            df = result.detailed_results\n",
    "            \n",
    "            # ì •ë‹µ ì˜ˆì‹œ\n",
    "            correct_samples = df[df['result'] == True]\n",
    "            incorrect_samples = df[df['result'] == False]\n",
    "            \n",
    "            if len(correct_samples) > 0 and len(incorrect_samples) > 0:\n",
    "                print(f\"\\n{'#'*5}\")\n",
    "                print(f\"{i+1}ë²ˆì§¸: {name} í”„ë¡¬í”„íŠ¸ ë¶„ì„\\n\")\n",
    "                \n",
    "                # ì •ë‹µ ì˜ˆì‹œ\n",
    "                true_sample = correct_samples.iloc[0]\n",
    "                print(f\"âœ… ì •ë‹µ ì˜ˆì‹œ:\")\n",
    "                print(f\"  ì˜ˆì¸¡: {true_sample['pred']}\")\n",
    "                print(f\"  ì •ë‹µ: {true_sample['answer']}\")\n",
    "                print(f\"  ì‘ë‹µ: {true_sample['response'][:200]}...\\n\")\n",
    "                \n",
    "                # ì˜¤ë‹µ ì˜ˆì‹œ\n",
    "                false_sample = incorrect_samples.iloc[0]\n",
    "                print(f\"âŒ ì˜¤ë‹µ ì˜ˆì‹œ:\")\n",
    "                print(f\"  ì˜ˆì¸¡: {false_sample['pred']}\")\n",
    "                print(f\"  ì •ë‹µ: {false_sample['answer']}\")\n",
    "                print(f\"  ì‘ë‹µ: {false_sample['response'][:200]}...\\n\")\n",
    "    \n",
    "    def export_detailed_results(self):\n",
    "        \"\"\"ìƒì„¸ ê²°ê³¼ë¥¼ JSONê³¼ CSVë¡œ ë‚´ë³´ë‚´ê¸°\"\"\"\n",
    "        if not self.results:\n",
    "            print(\"ë‚´ë³´ë‚¼ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            return\n",
    "        \n",
    "        # JSON í˜•íƒœë¡œ ìš”ì•½ ê²°ê³¼ ì €ì¥\n",
    "        summary_data = []\n",
    "        for name, result in self.results.items():\n",
    "            summary_data.append({\n",
    "                'model': str(result.model),                  \n",
    "                'prompt_method': str(result.prompt_method),\n",
    "                'total_score': float(result.total_score),     \n",
    "                'score_percentage': float(result.score),\n",
    "                'correct_answers': int(result.correct_answers), \n",
    "                'total_questions': int(result.total_questions),\n",
    "                'execution_time': float(result.execution_time)\n",
    "            })\n",
    "        \n",
    "        os.makedirs(\"data/results\", exist_ok=True)\n",
    "        with open(\"data/results/summary_results.json\", 'w', encoding='utf-8') as f:\n",
    "            json.dump(summary_data, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        print(f\"\\nğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ:\")\n",
    "        print(f\"   - ìš”ì•½: data/results/summary_results.json\")\n",
    "        print(f\"   - ìƒì„¸: data/results/ í´ë”ì˜ ê° CSV íŒŒì¼ë“¤\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜\"\"\"\n",
    "    solver = KoreanSuneungSolver()\n",
    "    \n",
    "    # API í‚¤ í™•ì¸\n",
    "    if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "        print(\"âŒ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "        print(\"OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ê±°ë‚˜ .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "        return\n",
    "    \n",
    "    # 1. ë°ì´í„° ë¡œë“œ\n",
    "    print(\"ğŸ“¥ ë°ì´í„° ë¡œë”© ì¤‘...\")\n",
    "    if not solver.load_data():\n",
    "        print(\"âŒ ë°ì´í„° ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. GitHub ì—°ê²°ì„ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "        return\n",
    "    \n",
    "    # 2. í…ŒìŠ¤íŠ¸ ë¬¸ì œ ìˆ˜ ì„¤ì •\n",
    "    total_problems = len(solver.data)\n",
    "    print(f\"ì „ì²´ ë¬¸ì œ ìˆ˜: {total_problems}\")\n",
    "    print(\"í…ŒìŠ¤íŠ¸í•  ë¬¸ì œ ìˆ˜ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì—”í„° ì‹œ ì „ì²´): \", end=\"\")\n",
    "    try:\n",
    "        user_input = input().strip()\n",
    "        if user_input:\n",
    "            test_count = int(user_input)\n",
    "            test_count = min(test_count, total_problems)\n",
    "        else:\n",
    "            test_count = None  # ì „ì²´ í…ŒìŠ¤íŠ¸\n",
    "    except:\n",
    "        test_count = 20  # ê¸°ë³¸ê°’\n",
    "        print(f\"ê¸°ë³¸ê°’ {test_count}ê°œ ë¬¸ì œë¡œ ì„¤ì •ë©ë‹ˆë‹¤.\")\n",
    "    \n",
    "    # 3. ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰\n",
    "    solver.run_comprehensive_test(max_questions=test_count)\n",
    "    \n",
    "    # 4. ê²°ê³¼ ë¶„ì„\n",
    "    solver.analyze_results()\n",
    "    \n",
    "    # 5. ê²°ê³¼ ë‚´ë³´ë‚´ê¸°\n",
    "    solver.export_detailed_results()\n",
    "    \n",
    "    print(f\"\\nğŸ‰ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
